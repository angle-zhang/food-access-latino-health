---
title: "2_prelim_results"
author: "Angela Zhang"
date: "2025-04-02"
output: html_document
---

```{r setup, include=FALSE}
source("0_Libraries.R")
library(kableExtra)
# run summarize measures
# source('2_summarize_measures')
```
# Planning document
- [Methods description is here](https://docs.google.com/document/d/1rAyl0qsaWPcxM4E1X8-hP70vpzbPF7CYUYRq4pbERDM/edit?tab=t.0)



# Sanity checks
✔️ We expect there to be 1424424 households in LA City
- We also want to see why some CTs are missing observations in the household aggregate measures
````{r}
nrow(la_city_hh) # 1424424
head(dt_household) 
length(unique(dt_household$id)) # 1424424
```
# Pull relevant values
```{r}
la_city <- get_city_boundary(proj_crs) %>%
  st_transform(proj_crs)

# get water
la_water <- area_water(state="CA", county="Los Angeles")%>%
  st_transform(proj_crs) %>%
  clipintersect_boundary(la_city)

osm_parks <- getbb("Los Angeles County", display_name_contains = "United States") %>%
  opq() %>% 
  add_osm_feature(key = "leisure", value=c("park", "nature_reserve", "golf_course")) %>%
  osmdata_sf()

la_parks <- osm_parks$osm_polygons %>%
  st_transform(proj_crs) %>%
  clipintersect_boundary(la_city)


```

### Visualize CT level data for all measures

```{r cars}
# visualize ct_level data
head(read.csv(paste0(processed_path, "/LAC_cleaned/ct_driving_times.csv"))) 

la_ct <- get_census_tracts(proj_crs, state="CA", year=2020, county="Los Angeles") %>%
  mutate(GEOID = as.numeric(GEOID)) 

# map census tract data 
# merge census tracts
# filter any missing data
ct_drive_data <- la_ct %>%
  merge(read_csv(paste0(processed_path, "/LAC_cleaned/ct_driving_times.csv")), by= "GEOID")

parcel_data <- la_ct |>
  merge(read_csv(paste0(processed_path, "LAC_cleaned/dt_household_ct.csv")))

```

### Inspecting missing census tract data in the household dataset
```{r}
# missing <- setdiff(as.numeric(la_city_ct$GEOID), as.numeric(ct_drive_data$GEOID))
# missing2 <- setdiff(as.numeric(la_city_ct$GEOID), as.numeric(la_city_hh$GEOID_20))

# plot census tract data for parcels 
tmap_mode("plot")
map <-  tm_shape(la_city) +
  tm_polygons(col="yellow") + 
  tm_shape(la_city_ct[la_city_ct$GEOID %in% missing,] ) + 
  tm_polygons(col= "red", alpha=.5) +
  tm_shape(ct_drive_data) +
  tm_polygons(col = "driving_FF_15_parcel_mean", style = "quantile", palette = "Blues", colorNA = NULL)

# see if la households datasets are different from processed data
la_city_hhn <- la_hh %>%
  filter(lengths(st_intersects(., st_transform(la_city, 4326))) > 0) 

la_city_hh <- la_hh %>%
  filter(GEOID_20 %in% la_city_ct$GEOID) %>%
  st_transform(4326)

missing2 <- setdiff(as.numeric(la_city_ct$GEOID), as.numeric(la_city_hh$GEOID_20))

print(map)
```


# Data analysis

## Plot histograms to observe distributions 
We find that many variables are not normally distributed so that leads us to select the Wilcoxon rank sum test to test differences in means between the various groups

*Todo* Additionally, we want to try to identify what type of measurement error/bias this could lead to which requires observing the distributions of the parcel-level values compared to the aggregate values (among other techniques). The figures below are a start

*Todo* look into the zero values for CT_CENT that are shown in the third figure
```{r}
dist <- ct_drive_data |>
  as.data.table() |>
  melt(measure.vars=c("ct_cent", "ct_wtcent", "parcel_mean")) 

ggplot(dist, aes(x=value, fill=variable, alpha=.5)) + 
   geom_step(stat = "bin", bins = 50, direction = "mid") +
  geom_histogram(bins = 50, alpha = 0.3, colour = NA,
    position = "identity") +
  facet_grid(cols=vars(type), rows=vars(drive), scales="free") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))


ggplot(dist |> filter(type=="SMK"), aes(x=value, col=variable, fill=variable, alpha=.3)) + 
  geom_step(stat = "bin", bins = 50, direction = "mid") +
  geom_histogram(bins = 50, alpha = 0.3, colour = NA,
    position = "identity") +
  #geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  facet_grid(rows=vars(drive), scales="free") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))

```
## Calculate t-tests to evaluate differences in distributions
```{r}
i=1
ttests0 <- split(ct_drive_data, list(ct_drive_data$type, ct_drive_data$drive)) %>%
  lapply(
  function(df) { 
    i <<- i+1
    print(length(df$parcel_mean))
      # paired n for each comparison (drops NAs pairwise)
    n1 <- sum(complete.cases(df$parcel_mean, df$ct_cent))
    n2 <- sum(complete.cases(df$ct_wtcent, df$ct_cent))
    n3 <- sum(complete.cases(df$parcel_mean, df$ct_wtcent))

    
    t1 <<- t.test(df$parcel_mean, df$ct_cent, paired=TRUE, alternative="two.sided")
    t2 <- t.test(df$ct_wtcent, df$ct_cent, paired=TRUE, alternative="two.sided")
    t3 <- t.test(df$parcel_mean, df$ct_wtcent, paired =TRUE, alternative="two.sided")

    
    drive <- unique(df$drive)[1]
    print(drive)
    type <- unique(df$type)[1]
    print(type)
    res <- data.frame(
      time_dist = unique(df$drive)[1], 
      type =  unique(df$type)[1],
      tests = c("parcel_cent", "wtcent_cent", "parcel_wtcent"), 
      n = c(n1, n2, n3),
      pval = c(t1$p.value, t2$p.value, t3$p.value),
      est = c(t1$estimate, t2$estimate, t3$estimate),
         conf.low  = c(t1$conf.int[1], t2$conf.int[1], t3$conf.int[1]),
      conf.high = c(t1$conf.int[2], t2$conf.int[2], t3$conf.int[2])
    )
    print(length(res))
    return(res)
  }
)

ttests <- ttests0 |>
  bind_rows()

ttests %>%
  select(type, time_dist, tests, n, est, conf.low, conf.high, pval) %>%
  kable(digits = 4, caption = "Paired t-test results") %>%
    row_spec(0, bold = TRUE, background = "white", color = "black") 

```
## Plotting results of t-test 
The results of the t-test shows that for longer drive time distances (>25 minutes), means of the census-tract level parcel measure are significantly different from means of the centroid calculated measure and means of population-centroid calculated measures 
```{r}
ggplot(ttests, aes(x=fct_relevel(tests, "parcel_cent", "wtcent_cent", "parcel_wtcent"), y=est, color=(pval<.05))) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  facet_grid(cols=vars(time_dist), rows=vars(type), scales="free") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))

ggplot(ct_drive_data, aes(x=parcel_mean, y=ct_wtcent)) + 
  geom_point(size=1, aes(alpha=.5)) + 
  #geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  facet_grid(cols=vars(drive), rows=vars(type), scales="fixed") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))

unique(ct_drive_data$type)

# TODO make table of the t-tests
# TODO make figure of t-tests

```
## Wilcox test results
Given that distributions of counts are not strictly following a normal distribution, we also perform a Wilcox test
```{r}
wtests0 <- split(ct_drive_data, list(ct_drive_data$type, ct_drive_data$drive)) %>%
  lapply(
  function(df) { 
   # i <<- i+1
    print(length(df$parcel_mean))
      # paired n for each comparison (drops NAs pairwise)
    n1 <- sum(complete.cases(df$parcel_mean, df$ct_cent))
    n2 <- sum(complete.cases(df$ct_wtcent, df$ct_cent))
    n3 <- sum(complete.cases(df$parcel_mean, df$ct_wtcent))

    
    t1 <<- wilcox.test(df$parcel_mean, df$ct_cent, paired=TRUE, alternative="two.sided")
    t2 <- wilcox.test(df$ct_wtcent, df$ct_cent, paired=TRUE, alternative="two.sided")
    t3 <- wilcox.test(df$parcel_mean, df$ct_wtcent, paired =TRUE, alternative="two.sided")

    drive <- unique(df$drive)[1]
    print(drive)
    type <- unique(df$type)[1]
    print(type)
    res <- data.frame(
      time_dist = unique(df$drive)[1], 
      type =  unique(df$type)[1],
      tests = c("parcel_cent", "wtcent_cent", "parcel_wtcent"), 
      n = c(n1, n2, n3),
      pval = c(t1$p.value, t2$p.value, t3$p.value)
      #est = c(t1$estimate, t2$estimate, t3$estimate),
      #conf.low  = c(t1$conf.int[1], t2$conf.int[1], t3$conf.int[1]),
      #conf.high = c(t1$conf.int[2], t2$conf.int[2], t3$conf.int[2])
    )
    print(length(res))
    return(res)
  }
)

wtests <- wtests0 |>
  bind_rows() |> 
  pivot_wider(values_from=pval, names_from=c(tests,n)) %>%
  select(type, time_dist, everything())%>%
  arrange(type)

wtests %>%
  #select(type, time_dist, tests, n, pval) %>%
  kable(digits = 4, caption = "Paired Wilcox (Mann Whitney U)-test results", booktabs = TRUE) %>%
  row_spec(0, bold = TRUE, background = "white", color = "black") |>
  kableExtra::collapse_rows(valign = "top")

unique(ct_drive_data$type)

```

## Map variation within CTs using parcel data
- map parcel data for one rural tract, one urban tract, one suburban tract
*todo* figure out why there are missing values for 5 minutes
- map coefficient of variation (dispersion) for each CT in LA City using parcel data
```{r}
tm_shape(parcel_data %>% drop_na(driving_SMK_20_parcel_cv)) + 
  tm_polygons(col="driving_SMK_5_parcel_cv", style="jenks") + tm_shape(la_water) +
  tm_fill(col="lightblue", lwd=0) 

tm_shape(parcel_data %>% drop_na(driving_SMK_20_parcel_cv)) + 
  tm_polygons(col="driving_SMK_10_parcel_cv", style="jenks") +  tm_shape(la_water) +
  tm_fill(col="lightblue", lwd=0) 

tm_shape(parcel_data %>% drop_na(driving_SMK_20_parcel_cv)) + 
  tm_polygons(col="driving_SMK_15_parcel_cv", style="jenks") + tm_shape(la_water) +
  tm_fill(col="lightblue", lwd=0) 

tm_shape(parcel_data %>% drop_na(driving_SMK_20_parcel_cv)) + 
  tm_polygons(col="driving_SMK_20_parcel_cv", style="jenks", legend.show = FALSE) +   
  tm_shape(la_water) +
  tm_fill(col="lightblue", lwd=0) + 
  tm_scale_bar(position=c("LEFT", "bottom"))
```

```{r}
cv <- ct_drive_data |>
  group_by(type, drive)

```
- repeat with ratio measures used in literature
```{r}




```

## Compare to health outcomes (need to generate evidence-based measures)
*TODO* 
- Urban vs Rural varied buffer time (e.g how the USDA does it) 
- Use ratio measures 
- Include USDA food access measures as a way to test importance 

## Map El Sendero data 
- need to link to geocoded data (ask beau for this?) 
```{r}
elsend <- read.csv("../../0_shared-data/latino-health-elsendero/raw/ElSenderoPathwaysToH_DATA_LABELS_2025-04-22_1153.csv")
elsend1 <- read.csv("../../0_shared-data/latino-health-elsendero/raw/ElSenderoPathwaysToH_DATA_LABELS_2025-04-22_1154.csv")

# map the results




```

